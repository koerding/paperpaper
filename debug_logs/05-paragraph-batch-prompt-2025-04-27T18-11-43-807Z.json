[
  {
    "role": "system",
    "content": "You evaluate the quality and structure of scientific paper paragraphs using established rules for effective writing."
  },
  {
    "role": "user",
    "content": "Evaluate each of these paragraphs from the \"The number of confounders is astronomical\" section according to these paragraph-level rules:\n\nRule 2B: Manage cognitive load for your readers\nThe vast knowledge base of human psychology is useful in paper writing. For example, people have working memory constraints in that they can only remember a small number of items and are better at remembering the beginning and the end of a list than the middle. Do your best to minimize the number of loose threads that the reader has to keep in mind at any one time.\n\nEvaluation criteria:\n- Average sentence length is under 25 words, with no sentence exceeding 40 words\n- Sentences have a Flesch-Kincaid readability score appropriate for scientific literature (Grade 12-16)\n- No more than 2-3 new technical concepts are introduced per paragraph\n- Logical structures (if-then, cause-effect) are not nested more than two levels deep\n- Paragraphs are limited to 4-6 sentences, focusing on a single idea or step\n\n\nRule 3B: Apply context-content-conclusion structure at the paragraph level\nThe C-C-C scheme defines the structure of the paper on multiple scales. Applying C-C-C at the paragraph scale, the first sentence defines the topic or context, the body hosts the novel content put forth for the reader's consideration, and the last sentence provides the conclusion to be remembered. Deviating from the C-C-C structure often leads to papers that are hard to read, but writers often do so because of their own autobiographical context. During our everyday lives as scientists, we spend a majority of our time producing content and a minority amidst a flurry of other activities. We run experiments, develop the exposition of available literature, and combine thoughts using the magic of human cognition. It is natural to want to record these efforts on paper and structure a paper chronologically. But for our readers, most details of our activities are extraneous. They do not care about the chronological path by which you reached a result; they just care about the ultimate claim and the logic supporting it. Thus, all our work must be reformatted to provide a context that makes our material meaningful and a conclusion that helps the reader to understand and remember it.\n\nEvaluation criteria:\n- First sentence of each paragraph establishes context or introduces the topic\n- Middle sentences provide evidence, data, or elaboration of the topic\n- Final sentence of each paragraph offers a conclusion or key takeaway\n- Paragraph organization follows logical rather than chronological structure\n- Each paragraph forms a complete thought unit with clear beginning, middle, and end\n\n\nRule 4B: Optimize logical flow using parallelism\nAcross consecutive paragraphs or sentences, parallel messages should be communicated with parallel form. Parallelism makes it easier to read the text because the reader is familiar with the structure. For example, if we have three independent reasons why we prefer one interpretation of a result over another, it is helpful to communicate them with the same syntax so that this syntax becomes transparent to the reader, which allows them to focus on the content. There is nothing wrong with using the same word multiple times in a sentence or paragraph. Resist the temptation to use a different word to refer to the same conceptâ€”doing so makes readers wonder if the second word has a slightly different meaning.\n\nEvaluation criteria:\n- Similar concepts are presented using similar grammatical structures and patterns\n- Same terms are used consistently for the same concepts throughout, avoiding synonyms that could suggest different meanings\n- Items in lists or series use parallel grammatical forms (all nouns, all verb phrases, etc.)\n- Sequence of similar points (e.g., arguments, examples, methods) follows consistent structural patterns\n- Similar sections (e.g., experiment descriptions) follow consistent organizational patterns\n\n\nRule 7C: Structure results paragraphs as question-data-answer units\nThe first results paragraph is special in that it typically summarizes the overall approach to the problem outlined in the introduction, along with any key innovative methods that were developed. Most readers do not read the methods, so this paragraph gives them the gist of the methods that were used. Each subsequent paragraph in the results section starts with a sentence or two that set up the question that the paragraph answers, such as the following: 'To verify that there are no artifacts...,' 'What is the test-retest reliability of our measure?,' or 'We next tested whether Ca2+ flux through L-type Ca2+ channels was involved.' The middle of the paragraph presents data and logic that pertain to the question, and the paragraph ends with a sentence that answers the question. For example, it may conclude that none of the potential artifacts were detected. This structure makes it easy for experienced readers to fact-check a paper. Each paragraph convinces the reader of the answer given in its last sentence. This makes it easy to find the paragraph in which a suspicious conclusion is drawn and to check the logic of that paragraph. The result of each paragraph is a logical statement, and paragraphs farther down in the text rely on the logical conclusions of previous paragraphs, much as theorems are built in mathematical literature.\n\nEvaluation criteria:\n- First paragraph of results summarizes the approach and key methods needed to understand findings\n- Each results paragraph begins by stating a question or purpose that will be addressed\n- Middle of each paragraph presents relevant data and evidence\n- Each results paragraph ends with a clear statement answering the initial question\n- Later paragraphs build on conclusions established in earlier paragraphs\n- Transitions between paragraphs create a coherent flow of experimental logic\n\n\nFor each paragraph, analyze:\n- Context-Content-Conclusion structure\n- Sentence quality (length under 25 words on average)\n- Topic continuity\n- Terminology consistency\n- Structural parallelism\n\nReturn a JSON object with this structure:\n{\n  \"evaluations\": [\n    {\n      \"text\": \"The original paragraph text\",\n      \"summary\": \"Brief summary of content\",\n      \"evaluations\": {\n        \"cccStructure\": boolean,\n        \"sentenceQuality\": boolean,\n        \"topicContinuity\": boolean,\n        \"terminologyConsistency\": boolean,\n        \"structuralParallelism\": boolean\n      },\n      \"issues\": [\n        {\n          \"issue\": \"Description of issue\",\n          \"severity\": \"critical | major | minor\",\n          \"recommendation\": \"Improvement suggestion\"\n        }\n      ]\n    }\n  ]\n}\n\nPARAGRAPHS:\nPARAGRAPH 1:\nOmitted variable biases will make causal inference impossible if there are many unobserved dimensions relative to the observed dimensions. For instance, when analyzing spike data, there are far more unobserved variables than observed variables. When we record a few hundred neurons [52], the number of recorded neurons is a vanishingly small subset of all neurons. We have little reason to assume that the recorded neurons are much more important than the un-recorded neurons. As each neuron receives inputs from so many other un-recorded neurons, we should expect that the parts of neural activity driven by unobserved neurons are arbitrarily larger than the parts coming from observed neurons. In other words, the confounding signal should be many orders of magnitude more important than those coming from observed data. As such, we should not expect that causal inference is possible.\n\nPARAGRAPH 2:\nWe might feel that causality may happen at a given scale, which would make the argument about unobserved dimensions invalid and allowing a multi-scale definition of interactions. The argument given is often the analogy to statistical physics: while understanding the interaction between individual gas molecules becomes quickly hopeless, a large set of gas atoms can be well understood in terms of temperature and pressure. However, this analogy quickly breaks down when applied to neurophysiology. Every neuron is special in the sense that they do not interact with random neurons, but with a largely fixed set, or worse, a set that changes through neuroplasticity. The justification of averaging over molecules is often perfectly fine in statistical physics. However, whether this this logic works in neuroscience remains an open question.\n\nPARAGRAPH 3:\nWhen analyzing imaging data such as fMRI, or LFP, EEG, or MEG, there are also far more unobserved variables than observed variables. Within each signal source, we can, in some abstraction, observe the sum of neural activity. However, the same measured activity can be realized by any combination of individual activities rendering a solution of the inverse problem (signals ðŸ¡ª neuronal spike trains) infeasible. The activity of neurons which are orthogonal to our signal, can span arbitrary dimensions, related to movement, memory, thought or neuronal communication. Importantly, dense physiological recordings in small areas suggest that countless variables are represented (e.g. movement related signals in V1; Musall et al., 2018; Stringer et al., 2018). The signals that we can measure are arbitrarily low-dimensional relative to the full dimensionality of communication in the brain. As such we are still in the situation where we have a number of confounders that is many orders of magnitude larger than the number of measured variables. This again puts us into the domain where causal inference should be impossible.\n\nPARAGRAPH 4:\nMacroscopic recording (such as fMRI) is what, to many people, hides the underlying logical problems of confounding. We record from a number of voxels or pixels. In many cases, we cover the whole brain. So where do the confounders hide? Within each voxel there are generally millions of neurons that form billions of synapses [50]. However, we only observe the macroscopic activities, say the sum of all activities. This means that all the dimensions that are uncorrelated to this sum continue to exist and continue to be transmitted to other voxels. In other words, there is nothing about the setting that removes confounders, unless the voxel activity itself is the confounder. Given that the majority of dimensions is unobserved, the probability of recording the confounder is vanishingly small.\n\nPARAGRAPH 5:\nIt has been argued that statistical approaches may still uncover low-dimensional organization between brain regions [2]. The argument is that if the brainâ€™s activity was very low dimensional and aligned with recorded dimensions [55], then recording from a small number of voxels or neurons may be equivalent to recording all of them. Such view assumes that we believe that the composition of the activity within a voxel, for instance, does not matter but just the measured sum of (unobserved) individual activities. We thereby effectively subscribe to a strong mean-field view, which is dominant among eC methodology [56â€“59]. However, within each voxel, we find neurons of countless tuning properties [60] that describe how neurons are affected by a stimulus dimension such as color. On a theoretical level, it thus becomes clear how mean-field or ensemble averaging techniques fall risk of violating ergodicity principles as a key assumption of cause-effect inference, i.e. that the mean response of representative samples allow predictions about individual members of those samples [61]. On a practical level, model inferences becomes easily biased when algorithms that compute eC based on mean-field variables (e.g. the average activity within several voxels informed by some parcellation)  miss relevant nodes [45,51]. Lastly we argue that effectively, mean-field studies set up simulations that unfold in low-dimensional spaces and then show that they can be recovered in low-dimensional spaces, rendering the approach somewhat circular [56â€“59]. To our knowledge no study has shown that networks that compute like brains can be approximated by the underlying mean-field approximation. Barring such a study we should assume that mean-field is not a meaningful approximation of brain computation.\n\nPARAGRAPH 6:\nTypically applied eC algorithms are unable to disentangle correlational from causal sources of variability regardless their mathematical sophistication [3,61]. Causal inference algorithms that work with observational data are generally built on the assumption of causal sufficiency, which boils down to there being no unobserved confounders (although see Ranganath and Perotte, 2018; Wang and Blei, 2018) â€“ this assumption within neuroscience is that all neurons are recorded from. Without these assumptions we can at best produce families of potential models and if any pair of recorded variables is confounded then this family will contain all models [64]. Recording only a few variables in a densely interacting causal system generally renders causal inference impossible [20,65].\n\nRespond ONLY with the JSON object."
  }
]