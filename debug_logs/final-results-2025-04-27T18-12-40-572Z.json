{
  "title": "Misleading causal statements in functional connectivity research",
  "abstract": {
    "text": "As neuroscientists we want to understand how causal interactions and mechanisms within the brain give rise to perception, cognition, and behavior. It has become popular to estimate interactions from measured activity using statistical techniques that aim to estimate ‚Äúfunctional connectivity‚Äù, and interpret these correlational estimates in causal terms. However, we argue that any given observed correlation can be explained by an infinite set of causal models that consider the unobserved variables. We show that the omitted variable bias equation makes this relation precise: as we only record low-dimensional signals from high-dimensional brains, the countless unobserved variables likely have more influence than the few observed ones. We argue that only brain perturbations allow approaching causality.",
    "summary": "The abstract discusses the challenges of interpreting functional connectivity in neuroscience, emphasizing the limitations of correlational estimates due to unobserved variables and advocating for brain perturbations to approach causality.",
    "issues": [
      {
        "issue": "The abstract introduces more than 2-3 new technical concepts, such as 'functional connectivity', 'causal models', and 'omitted variable bias equation', which may overwhelm the reader.",
        "severity": "major",
        "recommendation": "Limit the introduction of new technical concepts to 2-3 per paragraph to manage cognitive load."
      },
      {
        "issue": "The abstract does not follow the context-content-conclusion structure clearly in each paragraph.",
        "severity": "major",
        "recommendation": "Ensure each paragraph starts with context, provides content, and ends with a conclusion to enhance readability."
      },
      {
        "issue": "The abstract lacks a clear question-data-answer structure, particularly in the results section.",
        "severity": "major",
        "recommendation": "Reorganize the abstract to include a question at the beginning, followed by data or evidence, and conclude with an answer or key takeaway."
      },
      {
        "issue": "The average sentence length is close to the upper limit, and some sentences are complex.",
        "severity": "minor",
        "recommendation": "Simplify sentence structures and ensure average sentence length remains comfortably under 25 words."
      }
    ]
  },
  "documentAssessment": {
    "titleQuality": {
      "score": 8,
      "assessment": "The title effectively communicates the central contribution regarding misleading causal statements in functional connectivity research.",
      "recommendation": "Ensure the title remains focused on the central theme of causality misinterpretation."
    },
    "abstractCompleteness": {
      "score": 7,
      "assessment": "The abstract provides a clear overview of the research problem and approach but could better emphasize the broader significance.",
      "recommendation": "Include a stronger statement on the broader implications of the findings."
    },
    "introductionStructure": {
      "score": 6,
      "assessment": "The introduction sets the context and identifies the gap but could more explicitly state the importance of addressing this gap.",
      "recommendation": "Enhance the introduction by clearly articulating the significance of the research gap."
    },
    "resultsOrganization": {
      "score": 5,
      "assessment": "The results are presented with some logical flow, but there are issues with clarity and coherence in connecting findings to the central claim.",
      "recommendation": "Reorganize the results to ensure a clear, logical progression that directly supports the central claim."
    },
    "discussionQuality": {
      "score": 6,
      "assessment": "The discussion summarizes key findings but lacks depth in addressing limitations and broader impacts.",
      "recommendation": "Expand on the limitations and discuss the broader impact of the findings more thoroughly."
    },
    "messageFocus": {
      "score": 7,
      "assessment": "The paper maintains a focus on the central theme of causality misinterpretation but occasionally diverges into secondary topics.",
      "recommendation": "Ensure all sections consistently reinforce the central message without unnecessary digressions."
    },
    "topicOrganization": {
      "score": 5,
      "assessment": "The paper has issues with topic organization, with some sections containing unrelated content and multiple topic shifts.",
      "recommendation": "Consolidate related ideas and minimize topic shifts to improve coherence and flow."
    }
  },
  "majorIssues": [
    {
      "issue": "The results section lacks a clear logical sequence that builds towards the central claim.",
      "location": "Results section",
      "severity": "major",
      "recommendation": "Reorganize the results to follow a logical sequence that directly supports the central claim, using clear transition statements."
    },
    {
      "issue": "The discussion does not adequately address the limitations of the study.",
      "location": "Discussion section",
      "severity": "major",
      "recommendation": "Explicitly acknowledge and discuss the limitations of the study, providing context and suggesting future research directions."
    }
  ],
  "overallRecommendations": [
    "Reorganize the results section to ensure a logical flow that supports the central claim.",
    "Enhance the discussion by thoroughly addressing study limitations and broader impacts.",
    "Improve topic organization by consolidating related ideas and minimizing unnecessary topic shifts."
  ],
  "statistics": {
    "critical": 3,
    "major": 19,
    "minor": 11
  },
  "sections": [
    {
      "name": "The estimated connectivity field does attempt to draw causal insights from correlations",
      "paragraphs": [
        {
          "text": "Functional connectivity research has become a substantial part of neuroscientific literature in recent years [1]. Typically studies uses observational methods to estimate ‚Äúconnectivity‚Äù via statistical techniques that aim to infer interactions from continuous valued brain signals [2,3]. The approaches that we call estimated connectivity (eC) in this paper convert measured signals into a statistical estimate of ‚Äúconnectivity.‚Äù",
          "summary": "Introduction to the concept of estimated connectivity in neuroscientific research.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "We argue that the eC field uses language that suggests causality and its results aim to drive downstream research as if it was causality. Terms used to describe its methodology include Granger Causality, functional connectivity (FC), information flow, effective connectivity and dynamic causal models [3]. The field does this despite the fact that other terms such as improvement in predictive power, correlations, conditional correlations, and model comparison can denote more precisely what is actually done. The language effectively redefines causality related terms in the English language. Connectivity implies a connection between two places. Causality implies cause and effect. Flow implies that something moves from one place to another. This set of re-definitions gives rise to the problem that eC approaches are often misunderstood by practicing neuroscientists [4].",
          "summary": "Critique of the language used in the eC field that suggests causality.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Some sentences exceed 25 words, increasing cognitive load.",
              "severity": "minor",
              "recommendation": "Break longer sentences into shorter ones to improve readability."
            }
          ]
        },
        {
          "text": "This misleading redefinition profoundly affects downstream science. Scientists write about connections within the brain minimizing the wiring length along which signals need to travel [5,6], but while the brain may want to minimize wiring length, it pays no price for correlations. They write about stimulation to control the network [7], which requires interactions to be causal. They write about ‚Äúusing causal FC methods to identify network mechanisms underlying cognitive computations in the human brain‚Äù [8], which implies that prediction is a sufficient (and not just necessary) criterion to justify causal inferences. They write about mechanistic interference to cure diseases [9], which again requires causality. Or they write about regions that ‚Äúcause more exchange of causal information‚Äù [10]. These examples show how correlations are assumed to indicate causality. Specifically, eC is often discussed as if it did reveal an approximate understanding of causality, and much of it is due to misleading use of words that imply causality in lay English and merely refer to algorithm properties in statistics.",
          "summary": "Discussion on how misleading language in eC affects scientific interpretations.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Some sentences exceed 25 words, increasing cognitive load.",
              "severity": "minor",
              "recommendation": "Break longer sentences into shorter ones to improve readability."
            }
          ]
        },
        {
          "text": "We ourselves fell for this interpretation. We wrote in 2008  ‚Äú [‚Ä¶] [estimated connectivity] methods have become staples of neural data analysis, and have revealed a great deal about the interactions between cortical and subcortical structures.‚Äù [11]. We could simply have said that models that use other activities as independent variables are good predictors.  With LFPs it was argued that ‚Äú[‚Ä¶] the relative weight of feedforward and lateral inputs in visual cortex is not fixed, but rather depends on stimulus contrast.‚Äù [12]. For EEG and MEG power coherence analyses, it was advocated that ‚Äú[‚Ä¶] amplitude correlation is an informative index of the large-scale cortical interactions that mediate cognition.‚Äù [13]. For fMRI data, other authors reported ‚Äú[‚Ä¶] changes in the architecture of functional connectivity patterns that promote learning from initial training through mastery of a simple motor skill.‚Äù [14]. However, all these approaches only reach level one in Pearl‚Äôs hierarchy of causation [15,16] ‚Äì they describe correlations. While the impossibility of making causal statements in such situations is well known [17,18], the field continues to make them. Indeed, a recent perspective paper by published by leading researchers in the eC field explicitly states that it strives causality, predominantly by refining eC measures [2].",
          "summary": "Reflection on past misinterpretations and the ongoing issue of causality claims in eC.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Some sentences exceed 25 words, increasing cognitive load.",
              "severity": "minor",
              "recommendation": "Break longer sentences into shorter ones to improve readability."
            }
          ]
        },
        {
          "text": "Algorithms claiming eC have been used exhaustively when analyzing brain data with the hope of getting at causality. Using a more accurate terminology could help in the interpretation and, clarify that our results remain foremost descriptive: Interregional, or interneural signal correlations captures what most techniques measure.",
          "summary": "Call for more accurate terminology to clarify the descriptive nature of eC results.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        }
      ]
    },
    {
      "name": "Defining causality",
      "paragraphs": [
        {
          "text": "It has been argued that the definition of causality in neuroscience is ambiguous [4,19]. Whenever we refer to causal interactions in this opinion paper, we will use the counterfactual definition. A variable causally influences another variable if a perturbation of the first variable would induce a change in the activity of another variable [15,20]. This approximates what we mean as neuroscientists: if we say a neuron influences another neuron, we mean that perturbing the first (e.g. electrically) would affect the second and if we say that a region influences another, we mean that perturbing the first region (e.g. magnetically) would affect the second. Hence, causality has an intuitively clear definition (counterfactuals or perturbation) and we should demand our statistical approaches to be measured against it (although see also Gomez-Marin, 2017). While there is significant debate about adequate definitions of causality in contemporary philosophical literature [22‚Äì25], we argue that neuroscientists by and large use our definition and will underscore this point with the way these scientists make claims in their papers. After all, this interpretation is what allows making claims about mechanism and clinical targets.",
          "summary": "The paragraph discusses the definition of causality in neuroscience, advocating for the counterfactual definition and its application in scientific claims.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Sentence length exceeds recommended average, with some sentences being complex.",
              "severity": "major",
              "recommendation": "Break down longer sentences into shorter, more manageable ones to improve readability."
            }
          ]
        }
      ]
    },
    {
      "name": "Box 1. Statistical methods to estimate ‚Äúconnectivity‚Äù",
      "paragraphs": [
        {
          "text": "A rich body of literature has described eC techniques: some techniques utilize granger causality [26], other techniques talk about information flow [27,28]. Another class more directly talks about Dynamic Causal Modeling [29]. Within the neuroimaging community the term effective connectivity (EC) is often used when causality is explicitly claimed but within our definition, they fall into our more expansive definition of eC. We will argue that all these approaches share the same logical weakness ‚Äì statistical confounding. This problem is often acknowledged by the statisticians developing these algorithms and yet generally ignored by the experimentalists using them. Yet, the lure of extracting causality from observational data is so powerful, that we cannot avoid feeling the pull of it and have ourselves referred to correlations in connectivity terms [11].",
          "summary": "The paragraph discusses various eC techniques and their common issue of statistical confounding.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Average sentence length exceeds 25 words.",
              "severity": "major",
              "recommendation": "Break down longer sentences into shorter ones to improve readability."
            },
            {
              "issue": "Lack of structural parallelism in listing techniques.",
              "severity": "minor",
              "recommendation": "Use a consistent grammatical structure when listing different eC techniques."
            }
          ]
        },
        {
          "text": "The field has also developed techniques for estimating the strength of connections between neurons based on simultaneous spike recordings. The underlying idea is that we want to predict each neuron‚Äôs spiking probability based on the activity of other observed neurons, typically expressed in form of mechanistic claims [30,31]. And indeed, if we record all neurons, they are noisy, and we know that from their transfer function we should be able to estimate the strength and nature of causal interactions [32]. These studies, too, were generally interpreted in causal terms [11,30]. Again, the lure of causality is so powerful that it affects interpretations.",
          "summary": "The paragraph describes techniques for estimating neuronal connections and their causal interpretations.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "Within the eC community one can delineate two main philosophies. Some authors use eC to describe replicable network properties of functional and anatomical neural data without directly attributing causal significance to interregional correlations [33‚Äì35]. Others interpret changes in parameter estimates in more explicitly causal terms such as contributing factors of pathophysiological processes [36,37], biological mechanisms in learning and cognition in healthy [38,39], as vulnerability mechanisms to develop certain disorders [40,41], or in terms neuroplasticity in the functional re-organization of the brain [37,42]. Common to both groups is the focus on making mechanistic claims. Indeed, recent bibliometric research suggests that the study of eC has become a substantial area in neuroimaging [1], and it is thus is important to obtain clarity about its interpretation. We argue, however, that neuroscientists systematically interpret their correlational findings as causal by the misleading use of words that suggest mechanisms and causality.",
          "summary": "The paragraph outlines two main philosophies in the eC community and the common issue of misinterpreting correlational findings as causal.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Average sentence length exceeds 25 words.",
              "severity": "major",
              "recommendation": "Shorten sentences to improve readability and manage cognitive load."
            },
            {
              "issue": "Lack of structural parallelism in listing interpretations.",
              "severity": "minor",
              "recommendation": "Use a consistent grammatical structure when listing different interpretations."
            }
          ]
        }
      ]
    },
    {
      "name": "Confounding",
      "paragraphs": [
        {
          "text": "The confounding problem is the existence of unobserved variables that affect the observed variables (both a potential upstream population A and a potential downstream population B) in a way that generally makes the estimation of causal effects impossible. It is easy to see why it is impossible to use any statistical techniques to estimate causal interactions in the presence of unobserved confounding. Let us say there is a causal influence from A to B. In this case, it is always possible to construct a common input C which will produce the same effect on B that A would have (e.g. by replicating A and feeding into C). Similarly, if there is no influence from A to B it is always possible to use a confounder to change A and B so that they now look like they do interact. Clearly there is an infinite set of potential causal interpretations of the same partially observed signals.",
          "summary": "Discusses the challenge of unobserved confounding variables in estimating causal effects.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "For example, let us say we are interested in the interactions between two neurons. Further, let us assume that there is a third neuron (confounder) that activates both neurons. In that case, if we see a correlation between the neurons we cannot know if it is due to the neurons interacting directly or through an induced interaction by the unobserved neuron. More generally, any joint distribution between two neurons could be induced by a single third neuron. Unobserved neurons or information can act as confounders for the inference of eC, threatening the validity of the results. This confounding problem is central to the statistical field of causal inference and it is generally acknowledged that, in typical situations, unobserved confounders render inferences about causality impossible.",
          "summary": "Illustrates confounding in neuron interactions and its impact on causal inference.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "We want to use Simpson's paradox to highlight the threat of confounding [43], in which unobserved interaction can either cancel out main effects, or artificially induce spurious main effects. Let us say that there are two brain states (e.g. related to two levels of attention), and that one state is associated with high activity of neuron A and low activity of neuron B while another is associated with low activity of neuron A and high activity of neuron B. But let us say that there is a positive instantaneous causal influence from one on the other. If we do not know the brain state (confounded) we may conclude that neuron A has a negative influence on the activity of neuron B. However, if we do know the brain state, we correctly see that A increases the activity of neuron B (Figure 1). This paradox shows how confounders with relevant structure can arbitrarily influence the resulting eC and can effectively destroy it.",
          "summary": "Uses Simpson's paradox to demonstrate how confounding can mislead causal inference.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "Indeed, in certain neuroimaging datasets it is possible to directly observe Simpson‚Äôs paradox. For instance, the choice of analysis parameters, such as seed regions, and the network they belong to, may mediate whether different FC methods yield similar, or orthogonal results [44]. Moreover, functional brain parcellations reconfigure based on the brain state [45].",
          "summary": "Observes Simpson's paradox in neuroimaging datasets and its dependence on analysis parameters.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "The paragraph lacks a clear conclusion or key takeaway.",
              "severity": "major",
              "recommendation": "Add a concluding sentence that summarizes the implications of observing Simpson's paradox in neuroimaging datasets."
            }
          ]
        },
        {
          "text": "These issues would maybe be a minor problem if we had reasons to believe that confounding is weak, i.e. if there were few unobserved confounders and that they would be weak. However, we will demonstrate that we have no reason to believe so, and that the number of such confounders is in fact larger by orders of magnitude (and their strength arguably roughly the same) than the observed signals. We will argue, based on the omitted variable bias equation (Box 2) that it is highly unlikely that an algorithm could identify the network of causal interactions.",
          "summary": "Argues that confounding is significant and challenges the identification of causal networks.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        }
      ]
    },
    {
      "name": "The omitted variable bias (OVB)",
      "paragraphs": [
        {
          "text": "Neuroimaging datasets (e.g. fMRI and MEG) are affected by obvious confounders including head motion and physiological processes. One dominant view is that correcting for obvious confounders improves causal inference irrespective of unobserved confounders [2]. However, for each obvious external controllable confounder there are countless internal unobservable ones [46]. Hence, while we agree that correcting for observed confounders improves the prediction of models, we argue that such view remains speculative when it comes to inferring causality for theoretical reasons that we lay out below.",
          "summary": "The paragraph discusses the impact of confounders on neuroimaging datasets and questions the effectiveness of correcting for observed confounders in causal inference.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "For better illustration, we refer to a linear system (see Box 2). However, we note that OVB equally applies to nonlinear systems [47,48] as, the existence of unobserved variables introduces a bias that persists, regardless the amount of data. Given the nature of recorded brain signals, there is no reason to believe that the observed variables (e.g. average activation in a voxel) should have more causal influence than the unobserved variables (e.g. any represented variable orthogonal to this). Signals recorded in neuroscience usually entail millions more unobserved signals than observed signals [49,50]. Hence, the unobserved noise is expected to be arbitrarily larger than the signal obtained from observed neural activity. Therefore, statistical techniques will fail to reveal causal insights from correlations unless we have strong additional prior knowledge about the system and its dynamics.",
          "summary": "The paragraph explains the persistence of omitted variable bias in both linear and nonlinear systems, emphasizing the dominance of unobserved variables in neuroscience data.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "One sentence exceeds 40 words, impacting readability.",
              "severity": "major",
              "recommendation": "Break down long sentences into shorter ones to improve clarity and manage cognitive load."
            }
          ]
        }
      ]
    },
    {
      "name": "Box 2. Mathematical demonstration of the omitted variable bias",
      "paragraphs": [
        {
          "text": "Let us assume that there is a set of variables x that are observed. We want to ask what the causal influence of x is on y. Both x and y may be neural activities that relate in a linear way to each other:",
          "summary": "Introduction of variables x and y and their potential causal relationship.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "+zùõø  (1)",
          "summary": "Equation representing the relationship between x, y, and z.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": false,
            "topicContinuity": false,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Equation presented without context or explanation.",
              "severity": "critical",
              "recommendation": "Provide context or integrate into a paragraph with explanation."
            }
          ]
        },
        {
          "text": "where  is the weight for the influence that signal x has on y. Further, ùõø is the weight of the noise term z, which includes other variables that we do not observe but that also have a causal influence on x and y. These unobserved variables introduce OVB onto the causal estimate of the influence of x and y. Importantly, OVB cannot be overcome by more data, it exists in the limit of infinite sized datasets. Further, following a simple back of the envelope calculation for the relevant effects studied in the FC and EC fields, OVB should, be orders of magnitude larger than the real signals, entirely rendering the techniques useless for their typical applications.",
          "summary": "Explanation of weights and the impact of unobserved variables on causal estimates.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Sentence length exceeds recommended average.",
              "severity": "major",
              "recommendation": "Break down longer sentences into shorter, clearer statements."
            }
          ]
        },
        {
          "text": "When we apply a linear regression model, we typically ignore z and calculate as a mean square error estimate:",
          "summary": "Introduction to the application of linear regression ignoring z.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "(2)",
          "summary": "Placeholder for an equation.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": false,
            "topicContinuity": false,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Equation presented without context or explanation.",
              "severity": "critical",
              "recommendation": "Provide context or integrate into a paragraph with explanation."
            }
          ]
        },
        {
          "text": "However, once we take the noise (z) into account, we can insert the equation for y (1) into the equation for :",
          "summary": "Introduction to considering noise in the regression model.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "(3)",
          "summary": "Placeholder for an equation.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": false,
            "topicContinuity": false,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Equation presented without context or explanation.",
              "severity": "critical",
              "recommendation": "Provide context or integrate into a paragraph with explanation."
            }
          ]
        },
        {
          "text": "In other words, the existence of unobserved variables introduces a bias that persists, regardless the amount of data (X). There is no reason to believe that the  contribute more variance than the . The correlations between x and z are typically relatively high [51]. In fact, neural signals recorded in neuroscience usually entail millions more unobserved signals than observed signals [49]. Hence, the signal from the z term is expected to be arbitrarily larger than the signal from x and statistical techniques are highly susceptible to OVB when applied to merely observational data.",
          "summary": "Discussion on the persistent bias due to unobserved variables and its implications.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Sentence length exceeds recommended average.",
              "severity": "major",
              "recommendation": "Break down longer sentences into shorter, clearer statements."
            }
          ]
        },
        {
          "text": "As the neural dimensionality (or speed of processing) in each measured signal increases, the temporal resolution decreases, the noise (or non-communication related signal) increases and hence the idea of extracting causality from observation becomes hopeless. Importantly, this is not a problem that can simply be solved by recording data from more subjects. This is a case where a problem can fundamentally not be solved.",
          "summary": "Conclusion on the limitations of extracting causality due to noise and dimensionality.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        }
      ]
    },
    {
      "name": "The number of confounders is astronomical",
      "paragraphs": [
        {
          "text": "Omitted variable biases will make causal inference impossible if there are many unobserved dimensions relative to the observed dimensions. For instance, when analyzing spike data, there are far more unobserved variables than observed variables. When we record a few hundred neurons [52], the number of recorded neurons is a vanishingly small subset of all neurons. We have little reason to assume that the recorded neurons are much more important than the un-recorded neurons. As each neuron receives inputs from so many other un-recorded neurons, we should expect that the parts of neural activity driven by unobserved neurons are arbitrarily larger than the parts coming from observed neurons. In other words, the confounding signal should be many orders of magnitude more important than those coming from observed data. As such, we should not expect that causal inference is possible.",
          "summary": "The paragraph discusses the challenge of omitted variable biases in causal inference due to the vast number of unobserved variables compared to observed ones in neural data.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "We might feel that causality may happen at a given scale, which would make the argument about unobserved dimensions invalid and allowing a multi-scale definition of interactions. The argument given is often the analogy to statistical physics: while understanding the interaction between individual gas molecules becomes quickly hopeless, a large set of gas atoms can be well understood in terms of temperature and pressure. However, this analogy quickly breaks down when applied to neurophysiology. Every neuron is special in the sense that they do not interact with random neurons, but with a largely fixed set, or worse, a set that changes through neuroplasticity. The justification of averaging over molecules is often perfectly fine in statistical physics. However, whether this this logic works in neuroscience remains an open question.",
          "summary": "The paragraph critiques the analogy between statistical physics and neurophysiology, highlighting the unique interaction patterns of neurons.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "When analyzing imaging data such as fMRI, or LFP, EEG, or MEG, there are also far more unobserved variables than observed variables. Within each signal source, we can, in some abstraction, observe the sum of neural activity. However, the same measured activity can be realized by any combination of individual activities rendering a solution of the inverse problem (signals ü°™ neuronal spike trains) infeasible. The activity of neurons which are orthogonal to our signal, can span arbitrary dimensions, related to movement, memory, thought or neuronal communication. Importantly, dense physiological recordings in small areas suggest that countless variables are represented (e.g. movement related signals in V1; Musall et al., 2018; Stringer et al., 2018). The signals that we can measure are arbitrarily low-dimensional relative to the full dimensionality of communication in the brain. As such we are still in the situation where we have a number of confounders that is many orders of magnitude larger than the number of measured variables. This again puts us into the domain where causal inference should be impossible.",
          "summary": "The paragraph explains the difficulty of causal inference in imaging data due to the high number of unobserved variables compared to observed ones.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Some sentences exceed the recommended length, increasing cognitive load.",
              "severity": "minor",
              "recommendation": "Break longer sentences into shorter ones to improve readability."
            }
          ]
        },
        {
          "text": "Macroscopic recording (such as fMRI) is what, to many people, hides the underlying logical problems of confounding. We record from a number of voxels or pixels. In many cases, we cover the whole brain. So where do the confounders hide? Within each voxel there are generally millions of neurons that form billions of synapses [50]. However, we only observe the macroscopic activities, say the sum of all activities. This means that all the dimensions that are uncorrelated to this sum continue to exist and continue to be transmitted to other voxels. In other words, there is nothing about the setting that removes confounders, unless the voxel activity itself is the confounder. Given that the majority of dimensions is unobserved, the probability of recording the confounder is vanishingly small.",
          "summary": "The paragraph discusses how macroscopic recordings like fMRI obscure the presence of confounders due to unobserved neuronal activities.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "It has been argued that statistical approaches may still uncover low-dimensional organization between brain regions [2]. The argument is that if the brain‚Äôs activity was very low dimensional and aligned with recorded dimensions [55], then recording from a small number of voxels or neurons may be equivalent to recording all of them. Such view assumes that we believe that the composition of the activity within a voxel, for instance, does not matter but just the measured sum of (unobserved) individual activities. We thereby effectively subscribe to a strong mean-field view, which is dominant among eC methodology [56‚Äì59]. However, within each voxel, we find neurons of countless tuning properties [60] that describe how neurons are affected by a stimulus dimension such as color. On a theoretical level, it thus becomes clear how mean-field or ensemble averaging techniques fall risk of violating ergodicity principles as a key assumption of cause-effect inference, i.e. that the mean response of representative samples allow predictions about individual members of those samples [61]. On a practical level, model inferences becomes easily biased when algorithms that compute eC based on mean-field variables (e.g. the average activity within several voxels informed by some parcellation) miss relevant nodes [45,51]. Lastly we argue that effectively, mean-field studies set up simulations that unfold in low-dimensional spaces and then show that they can be recovered in low-dimensional spaces, rendering the approach somewhat circular [56‚Äì59]. To our knowledge no study has shown that networks that compute like brains can be approximated by the underlying mean-field approximation. Barring such a study we should assume that mean-field is not a meaningful approximation of brain computation.",
          "summary": "The paragraph critiques the mean-field approach in neuroscience, highlighting its limitations and potential biases.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Some sentences exceed the recommended length, increasing cognitive load.",
              "severity": "minor",
              "recommendation": "Break longer sentences into shorter ones to improve readability."
            }
          ]
        },
        {
          "text": "Typically applied eC algorithms are unable to disentangle correlational from causal sources of variability regardless their mathematical sophistication [3,61]. Causal inference algorithms that work with observational data are generally built on the assumption of causal sufficiency, which boils down to there being no unobserved confounders (although see Ranganath and Perotte, 2018; Wang and Blei, 2018) ‚Äì this assumption within neuroscience is that all neurons are recorded from. Without these assumptions we can at best produce families of potential models and if any pair of recorded variables is confounded then this family will contain all models [64]. Recording only a few variables in a densely interacting causal system generally renders causal inference impossible [20,65].",
          "summary": "The paragraph discusses the limitations of eC algorithms in distinguishing causal relationships due to the assumption of causal sufficiency.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        }
      ]
    },
    {
      "name": "Why higher resolution is not the solution",
      "paragraphs": [
        {
          "text": "We may ask if causal inference may work for exhaustively recorded (i.e., completely observed) neural networks, for instance in small animals or engineered systems. In the worm c. elegans, aplysia, drosophila, larval zebrafish [66] or microprocessors [67] recording all ‚Äúneurons‚Äù at high temporal precision is possible. For instance, in very small simulated systems that contain only a few interconnected neurons we may find that correlation approaches true, causal connectivity (https://compneuro.neuromatch.io/tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial2.html). However, once the network becomes larger (or, equivalently, there being stronger spatial autocorrelation, estimated and true connectivity diverge, and model identification becomes impossible (Figure 2). Likewise, model inference based on merely observational data (i.e. network correlations) becomes impossible in larger, interconnected systems. This is because mismatches between the generative system and the inference model (i.e. model mis-specification) become inevitable , and highly correlated, yet not directly coupled activity (as typically observed in recurrent networks) will be easily mistaken for direct connections [51]. This underdetermination (or ‚Äúmissing region‚Äù problem and the bias it introduces is well known [29,51] and only controlled perturbations can prevent such systematic inference errors [51,68].",
          "summary": "The paragraph discusses the challenges of causal inference in neural networks, particularly as network size increases.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Sentence length exceeds recommended average, with some sentences being complex.",
              "severity": "major",
              "recommendation": "Break down longer sentences into shorter, more manageable ones."
            },
            {
              "issue": "Lack of structural parallelism in presenting examples and consequences.",
              "severity": "minor",
              "recommendation": "Use parallel structures when listing examples or consequences to improve readability."
            }
          ]
        },
        {
          "text": "As the impossibility of causal inference from subsampled data may feel counter-intuitive we want to spell out the problem a bit more. Let us assume we are interested in the connections between two signals, e.g. voxels B and C. However, we note the brain‚Äôs real dynamics are characterized by the activity of up to more than 5 million neurons contained in these voxels [50]. In its simplest form, these can be modelled as a linear system that includes a noise term for unexplained variance. As the neural dimensionality (or speed of processing) in each measured signal increases, the noise (or non-communication related signal) increases and hence the idea of extracting causality from observation becomes hopeless. Importantly, this is not a problem that can simply be solved by recording data from more observations. Increasing data can only decrease variance errors but not bias errors, which result from correlated neural activities that are not averaged out by merely increasing data [51]. Bias errors will persist unless perturbations are applied [51].",
          "summary": "The paragraph explains why causal inference from subsampled data is problematic, emphasizing the role of noise and bias errors.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "For all methods that we have at our disposal to run functional connectivity analyses, the signals are few relative to the many unobserved variables. In these settings, interactions between measured signals should describe much less variance than the interactions between unobserved variables. While the examples we discuss here focus on neuron-to-neuron interactions, additional complexity arises from interactions with other cell types such as glia. Just like in Simpson‚Äôs paradox, the interactions between such unobserved variables can arbitrarily affect the estimates of interactions between measured signals [49]. As the neural dimensionality in each measured signal increases, the noise (or non-communication related signal) increases and interactions between unobserved variables can arbitrarily affect the estimates of interactions between measured signals, resulting in OVB [68]. Hence, all reviewed statistical methods are ultimately susceptible to OVB [48,69,70].",
          "summary": "The paragraph highlights the limitations of functional connectivity analyses due to unobserved variables and their impact on observed signal interactions.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Sentence length exceeds recommended average, with some sentences being complex.",
              "severity": "major",
              "recommendation": "Break down longer sentences into shorter, more manageable ones."
            }
          ]
        }
      ]
    },
    {
      "name": "Correct ‚Äúestimated connectivity‚Äù from perturbations",
      "paragraphs": [
        {
          "text": "A continuum of perturbation approaches to study causal interactions in brain activity are available in the neurosciences that should motivate future developments [19]. Counterfactual, causal inference ideas can be used to assess the strength of evidence about causality that can be obtained with commonly used approaches. Considerations of the Bradford-Hill criteria, provide a starting point for future research on causality in neuroscience. These perturbation studies also come with limitations, e.g. sources of confounding and still limited understanding of involved mechanisms [73,74]. Istill for those studies However, perturbation and in particular (passive) brain stimulation techniques are currently as close as we can get to causality in neuroscience when employed in a randomized, adequately controlled and blinded way [75].",
          "summary": "The paragraph discusses the use of perturbation approaches in neuroscience to study causal interactions, highlighting both their potential and limitations.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Sentence exceeds 40 words and contains grammatical errors.",
              "severity": "major",
              "recommendation": "Break down complex sentences and correct grammatical errors for clarity."
            },
            {
              "issue": "Lack of structural parallelism in presenting limitations and potential.",
              "severity": "minor",
              "recommendation": "Use parallel structure to present limitations and potential consistently."
            }
          ]
        },
        {
          "text": "Emerging techniques for perturbations may confront us with new conceptual problems. Perturbation techniques such as neurofeedback training and brain computer interfaces (BCIs) may be seen as an approximation to direct perturbations [79], because they allow to entrain correlations between brain regions and test for desired behavioral changes and have thus been advocated as tools for trying to understand causality within the brain [80‚Äì82]. BCIs synchronized in multiple users (so called hyperscanning) provide a special use case that allows closed-loop control of neural synchrony. These developments have recently initiated debates about causal inferences that can be drawn from well-controlled BCI experiments [83‚Äì86]. As complex interventions BCIs entail various obvious confounders and require experiments with (often many) carefully designed control conditions [87]. Combining BCIs with brain stimulation techniques may circumvent some limitations of other approaches. Further, complementary invasive closed-loop optogenetic stimulation studies conducted in animals, where stimulation is triggered by learned neural activity patterns [88], may circumvent some of the confounders and provide converging evidence [19,89]. Conceptual work is needed, however, to obtain clarity about these interpretations.",
          "summary": "The paragraph explores emerging perturbation techniques like BCIs and their conceptual challenges, including confounders and the need for control conditions.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Average sentence length exceeds 25 words.",
              "severity": "major",
              "recommendation": "Shorten sentences to improve readability and manage cognitive load."
            }
          ]
        },
        {
          "text": "Lastly, clinical applications often use eC measures, not to quantify causal interactions but as a proxy for hard-to measure behavioral effects. Clinicians ask if interventions affect eC as ‚Äúbiomarkers‚Äù. Brain stimulation techniques can thus be ‚ÄúeC-navigated‚Äù, i.e. targets are defined based on eC measures that predict (individual) clinical outcomes [90]. Brain Computer interfaces (BCIs) can target eC measures using eC changes as readily optimizable targets [83,91]. eC may be the best quantitative biomarkers for intervention effects when tested in adequately designed randomized controlled trials. They may also enable a quest to understand if low-dimensional organization principles can approximate causality [2]. However, research based on eC biomarkers remain somewhat circular field where changes in low-dimensional space are used to justify low-dimensional assumptions (e.g. mean-field based eC between two brain regions). Thus, causal insight about eC biomarkers (e.g. when used in eC-navigated perturbations) will require converging evidence [19] across organisational levels of the nervous system (i.e. molecular mechanisms) [49] and, above all, tests based on perturbations.",
          "summary": "The paragraph discusses the use of eC measures in clinical applications as biomarkers and the challenges in deriving causal insights.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Average sentence length exceeds 25 words.",
              "severity": "major",
              "recommendation": "Break down complex sentences to improve readability."
            }
          ]
        }
      ]
    },
    {
      "name": "Concluding remarks",
      "paragraphs": [
        {
          "text": "We have reviewed why eC approaches cannot meaningfully get at causality due to massive confounding from unobserved variables ‚Äì correlations are not causation and omitted variables produce biases. However, this circumstance does not imply that trying to understand the joint dynamics of many neurons or brain areas is not interesting. For example, looking at the brain in lower dimensional projections may allow us to see its invariances [92‚Äì94]. Interregional correlations may have no causal meaning, but they may allow us to derive biomarkers [95‚Äì97]. To which degree these reflect neuronal interactions, however, remains subject to future perturbational, well controlled studies. Understanding joint statistics of neurons or brain networks is highly informative, however, statements about joint statistics are not meaningful statements about causality ‚Äì it is important to be clear about the statements permitted by any one approach. In cases where these cannot be substantiated, only descriptive approaches [98] non-causal explanations are informative and meaningful [25,99]. Lastly, we note that there may be also a sociological dimension to the raised issues: authors often seem incited to make causal statements using filler verbs (e.g. to drive, alter, promote) as a form of storytelling [21] to leverage the perceived attractiveness of their work. Instead of committing this fallacy, we encourage researchers to question the causal validity of statements, probe underlying assumptions and test counterfactual inference boundaries (see Outstanding questions).",
          "summary": "The paragraph discusses the limitations of eC approaches in establishing causality due to confounding variables, the potential value of understanding joint dynamics of neurons, and the sociological tendency to make causal claims.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "The paragraph lacks a clear context-content-conclusion structure.",
              "severity": "major",
              "recommendation": "Reorganize the paragraph to clearly establish context, provide content, and conclude with a key takeaway."
            },
            {
              "issue": "Average sentence length exceeds 25 words, with some sentences being complex.",
              "severity": "major",
              "recommendation": "Break down longer sentences into shorter, more digestible ones."
            },
            {
              "issue": "The paragraph introduces multiple ideas without clear structural parallelism.",
              "severity": "minor",
              "recommendation": "Use parallel structures to present similar ideas or arguments for better readability."
            }
          ]
        }
      ]
    },
    {
      "name": "Outstanding questions",
      "paragraphs": [
        {
          "text": "What is an adequate nomenclature for causality inferences in neuroscience that reflects the different degree of uncertainty associated with individual approaches?",
          "summary": "The paragraph questions the appropriate terminology for causality inferences in neuroscience.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "The paragraph lacks a content and conclusion, only posing a question.",
              "severity": "major",
              "recommendation": "Expand the paragraph to include context and a potential conclusion or implication of the question."
            }
          ]
        },
        {
          "text": "For which questions do we need causality? For instance, clinical research may find biomarkers that indicate a disease state but are not part of the causal chain or about which we have little mechanistic insight. Yet, they may be suitable to predict disease trajectories or treatment response.",
          "summary": "The paragraph discusses the necessity of causality in clinical research, particularly regarding biomarkers.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "What are the counterfactual inference boundaries for perturbation approaches and how can these be considered with adequate analyses? There are several approaches that may be useful, for instance tests and simulation studies that investigate under which circumstances there is likely confounding by Simpson‚Äôs paradox. In neural systems that are fully described, targeted perturbations can be used to probe whether algorithms can reconstruct expected patterns.",
          "summary": "The paragraph explores the boundaries of counterfactual inference in perturbation approaches and suggests methods to address confounding factors.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "Which mechanisms underly effects of perturbational approaches such as brain stimulations and BCIs? How can study protocols for combined perturbational approaches be optimized to yield converging causal mapping?",
          "summary": "The paragraph questions the mechanisms of perturbational approaches and how protocols can be optimized for causal mapping.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "The paragraph lacks a content and conclusion, only posing questions.",
              "severity": "major",
              "recommendation": "Provide context and potential conclusions or implications for the questions posed."
            }
          ]
        }
      ]
    }
  ]
}