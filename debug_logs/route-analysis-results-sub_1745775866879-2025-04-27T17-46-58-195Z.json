{
  "title": "Misleading causal statements in functional connectivity research",
  "abstract": {
    "text": "As neuroscientists we want to understand how causal interactions and mechanisms within the brain give rise to perception, cognition, and behavior. It has become popular to estimate interactions from measured activity using statistical techniques that aim to estimate “functional connectivity”, and interpret these correlational estimates in causal terms. However, we argue that any given observed correlation can be explained by an infinite set of causal models that consider the unobserved variables. We show that the omitted variable bias equation makes this relation precise: as we only record low-dimensional signals from high-dimensional brains, the countless unobserved variables likely have more influence than the few observed ones. We argue that only brain perturbations allow approaching causality.",
    "summary": "The abstract discusses the challenges in understanding causal interactions in the brain using functional connectivity estimates, highlighting the limitations due to unobserved variables and suggesting brain perturbations as a more reliable approach to infer causality.",
    "issues": [
      {
        "issue": "Average sentence length exceeds 25 words, with one sentence containing 39 words.",
        "severity": "minor",
        "recommendation": "Break longer sentences into shorter ones to improve readability and manage cognitive load."
      },
      {
        "issue": "The abstract introduces more than 2-3 new technical concepts, such as 'functional connectivity', 'causal models', and 'omitted variable bias equation'.",
        "severity": "major",
        "recommendation": "Limit the introduction of new technical concepts to 2-3 per paragraph to reduce cognitive load."
      },
      {
        "issue": "The paragraph does not follow the context-content-conclusion structure effectively.",
        "severity": "major",
        "recommendation": "Reorganize the paragraph to clearly establish the context, provide detailed content, and conclude with a key takeaway."
      },
      {
        "issue": "Parallelism is not effectively used; similar concepts are not presented using similar grammatical structures.",
        "severity": "minor",
        "recommendation": "Use consistent grammatical structures when presenting similar concepts to enhance readability."
      }
    ]
  },
  "documentAssessment": {
    "titleQuality": {
      "score": 7,
      "assessment": "The title captures the central theme of misleading causal statements in functional connectivity research.",
      "recommendation": "Consider making the title more specific to the main finding or contribution of the paper."
    },
    "abstractCompleteness": {
      "score": 6,
      "assessment": "The abstract identifies the problem and suggests a solution but lacks a clear statement of broader significance.",
      "recommendation": "Include a sentence on the broader impact of the findings to enhance the abstract's completeness."
    },
    "introductionStructure": {
      "score": 8,
      "assessment": "The introduction effectively sets up the context and identifies the research gap.",
      "recommendation": "Ensure the introduction clearly states the importance of addressing the identified gap."
    },
    "resultsOrganization": {
      "score": 5,
      "assessment": "Results are presented with some logical flow but are occasionally interrupted by unrelated content.",
      "recommendation": "Reorganize the results to maintain a clear logical progression supporting the central claim."
    },
    "discussionQuality": {
      "score": 6,
      "assessment": "The discussion addresses limitations and broader impacts but lacks a strong synthesis of results.",
      "recommendation": "Strengthen the synthesis of results and their implications for the field."
    },
    "messageFocus": {
      "score": 5,
      "assessment": "The paper has multiple sections that diverge from the central message, affecting focus.",
      "recommendation": "Consolidate sections to maintain a clear focus on the central contribution."
    },
    "topicOrganization": {
      "score": 4,
      "assessment": "Topics are scattered, with frequent shifts that disrupt the logical flow.",
      "recommendation": "Group related ideas and minimize topic shifts to improve coherence."
    }
  },
  "majorIssues": [
    {
      "issue": "Frequent topic shifts and scattered presentation of related ideas.",
      "location": "Throughout the results and discussion sections.",
      "severity": "major",
      "recommendation": "Reorganize the paper to consolidate related topics and maintain a logical flow."
    }
  ],
  "overallRecommendations": [
    "Reorganize the results and discussion sections to improve logical flow and coherence.",
    "Enhance the abstract by including the broader significance of the findings.",
    "Ensure the title and introduction clearly reflect the central contribution and its importance."
  ],
  "statistics": {
    "critical": 5,
    "major": 19,
    "minor": 10
  },
  "sections": [
    {
      "name": "The estimated connectivity field does attempt to draw causal insights from correlations",
      "paragraphs": [
        {
          "text": "Functional connectivity research has become a substantial part of neuroscientific literature in recent years [1]. Typically studies uses observational methods to estimate “connectivity” via statistical techniques that aim to infer interactions from continuous valued brain signals [2,3]. The approaches that we call estimated connectivity (eC) in this paper convert measured signals into a statistical estimate of “connectivity.”",
          "summary": "Introduction to functional connectivity research and estimated connectivity (eC).",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "We argue that the eC field uses language that suggests causality and its results aim to drive downstream research as if it was causality. Terms used to describe its methodology include Granger Causality, functional connectivity (FC), information flow, effective connectivity and dynamic causal models [3]. The field does this despite the fact that other terms such as improvement in predictive power, correlations, conditional correlations, and model comparison can denote more precisely what is actually done. The language effectively redefines causality related terms in the English language. Connectivity implies a connection between two places. Causality implies cause and effect. Flow implies that something moves from one place to another. This set of re-definitions gives rise to the problem that eC approaches are often misunderstood by practicing neuroscientists [4].",
          "summary": "Discussion on the misleading use of causality-related language in the eC field.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Some sentences exceed 25 words, increasing cognitive load.",
              "severity": "minor",
              "recommendation": "Break longer sentences into shorter ones to improve readability."
            }
          ]
        },
        {
          "text": "This misleading redefinition profoundly affects downstream science. Scientists write about connections within the brain minimizing the wiring length along which signals need to travel [5,6], but while the brain may want to minimize wiring length, it pays no price for correlations. They write about stimulation to control the network [7], which requires interactions to be causal. They write about “using causal FC methods to identify network mechanisms underlying cognitive computations in the human brain” [8], which implies that prediction is a sufficient (and not just necessary) criterion to justify causal inferences. They write about mechanistic interference to cure diseases [9], which again requires causality. Or they write about regions that “cause more exchange of causal information” [10]. These examples show how correlations are assumed to indicate causality. Specifically, eC is often discussed as if it did reveal an approximate understanding of causality, and much of it is due to misleading use of words that imply causality in lay English and merely refer to algorithm properties in statistics.",
          "summary": "Impact of misleading causality language on scientific interpretations and assumptions.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Some sentences exceed 25 words, increasing cognitive load.",
              "severity": "minor",
              "recommendation": "Break longer sentences into shorter ones to improve readability."
            }
          ]
        },
        {
          "text": "We ourselves fell for this interpretation. We wrote in 2008 “ […] [estimated connectivity] methods have become staples of neural data analysis, and have revealed a great deal about the interactions between cortical and subcortical structures.” [11]. We could simply have said that models that use other activities as independent variables are good predictors. With LFPs it was argued that “[…] the relative weight of feedforward and lateral inputs in visual cortex is not fixed, but rather depends on stimulus contrast.” [12]. For EEG and MEG power coherence analyses, it was advocated that “[…] amplitude correlation is an informative index of the large-scale cortical interactions that mediate cognition.” [13]. For fMRI data, other authors reported “[…] changes in the architecture of functional connectivity patterns that promote learning from initial training through mastery of a simple motor skill.” [14]. However, all these approaches only reach level one in Pearl’s hierarchy of causation [15,16] – they describe correlations. While the impossibility of making causal statements in such situations is well known [17,18], the field continues to make them. Indeed, a recent perspective paper by published by leading researchers in the eC field explicitly states that it strives causality, predominantly by refining eC measures [2].",
          "summary": "Authors' reflection on their own past misinterpretations and the persistence of causality claims.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Some sentences exceed 25 words, increasing cognitive load.",
              "severity": "minor",
              "recommendation": "Break longer sentences into shorter ones to improve readability."
            }
          ]
        },
        {
          "text": "Algorithms claiming eC have been used exhaustively when analyzing brain data with the hope of getting at causality. Using a more accurate terminology could help in the interpretation and, clarify that our results remain foremost descriptive: Interregional, or interneural signal correlations captures what most techniques measure.",
          "summary": "Call for accurate terminology to clarify the descriptive nature of eC results.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        }
      ]
    },
    {
      "name": "Defining causality",
      "paragraphs": [
        {
          "text": "It has been argued that the definition of causality in neuroscience is ambiguous [4,19]. Whenever we refer to causal interactions in this opinion paper, we will use the counterfactual definition. A variable causally influences another variable if a perturbation of the first variable would induce a change in the activity of another variable [15,20]. This approximates what we mean as neuroscientists: if we say a neuron influences another neuron, we mean that perturbing the first (e.g. electrically) would affect the second and if we say that a region influences another, we mean that perturbing the first region (e.g. magnetically) would affect the second. Hence, causality has an intuitively clear definition (counterfactuals or perturbation) and we should demand our statistical approaches to be measured against it (although see also Gomez-Marin, 2017). While there is significant debate about adequate definitions of causality in contemporary philosophical literature [22–25], we argue that neuroscientists by and large use our definition and will underscore this point with the way these scientists make claims in their papers. After all, this interpretation is what allows making claims about mechanism and clinical targets.",
          "summary": "The paragraph discusses the ambiguity of causality definitions in neuroscience, advocating for the counterfactual definition as it aligns with neuroscientific practices.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Average sentence length exceeds 25 words, with some sentences being complex.",
              "severity": "major",
              "recommendation": "Break down longer sentences into shorter ones to improve readability and manage cognitive load."
            }
          ]
        }
      ]
    },
    {
      "name": "Box 1. Statistical methods to estimate “connectivity”",
      "paragraphs": [
        {
          "text": "A rich body of literature has described eC techniques: some techniques utilize granger causality [26], other techniques talk about information flow [27,28]. Another class more directly talks about Dynamic Causal Modeling [29]. Within the neuroimaging community the term effective connectivity (EC) is often used when causality is explicitly claimed but within our definition, they fall into our more expansive definition of eC. We will argue that all these approaches share the same logical weakness – statistical confounding. This problem is often acknowledged by the statisticians developing these algorithms and yet generally ignored by the experimentalists using them. Yet, the lure of extracting causality from observational data is so powerful, that we cannot avoid feeling the pull of it and have ourselves referred to correlations in connectivity terms [11].",
          "summary": "The paragraph discusses various eC techniques and their common issue of statistical confounding.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Average sentence length exceeds 25 words.",
              "severity": "major",
              "recommendation": "Break down longer sentences into shorter ones to improve readability."
            },
            {
              "issue": "Lack of structural parallelism in listing techniques.",
              "severity": "minor",
              "recommendation": "Use a consistent structure when listing different eC techniques."
            }
          ]
        },
        {
          "text": "The field has also developed techniques for estimating the strength of connections between neurons based on simultaneous spike recordings. The underlying idea is that we want to predict each neuron’s spiking probability based on the activity of other observed neurons, typically expressed in form of mechanistic claims [30,31]. And indeed, if we record all neurons, they are noisy, and we know that from their transfer function we should be able to estimate the strength and nature of causal interactions [32]. These studies, too, were generally interpreted in causal terms [11,30]. Again, the lure of causality is so powerful that it affects interpretations.",
          "summary": "The paragraph describes techniques for estimating neuronal connections and their causal interpretations.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "Within the eC community one can delineate two main philosophies. Some authors use eC to describe replicable network properties of functional and anatomical neural data without directly attributing causal significance to interregional correlations [33–35]. Others interpret changes in parameter estimates in more explicitly causal terms such as contributing factors of pathophysiological processes [36,37], biological mechanisms in learning and cognition in healthy [38,39], as vulnerability mechanisms to develop certain disorders [40,41], or in terms neuroplasticity in the functional re-organization of the brain [37,42]. Common to both groups is the focus on making mechanistic claims. Indeed, recent bibliometric research suggests that the study of eC has become a substantial area in neuroimaging [1], and it is thus is important to obtain clarity about its interpretation. We argue, however, that neuroscientists systematically interpret their correlational findings as causal by the misleading use of words that suggest mechanisms and causality.",
          "summary": "The paragraph outlines two main philosophies in the eC community and the common issue of misinterpreting correlational findings as causal.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Average sentence length exceeds 25 words.",
              "severity": "major",
              "recommendation": "Shorten sentences to improve readability."
            },
            {
              "issue": "Lack of structural parallelism in listing interpretations.",
              "severity": "minor",
              "recommendation": "Use a consistent structure when listing different interpretations."
            }
          ]
        }
      ]
    },
    {
      "name": "Confounding",
      "paragraphs": [
        {
          "text": "The confounding problem is the existence of unobserved variables that affect the observed variables (both a potential upstream population A and a potential downstream population B) in a way that generally makes the estimation of causal effects impossible. It is easy to see why it is impossible to use any statistical techniques to estimate causal interactions in the presence of unobserved confounding. Let us say there is a causal influence from A to B. In this case, it is always possible to construct a common input C which will produce the same effect on B that A would have (e.g. by replicating A and feeding into C). Similarly, if there is no influence from A to B it is always possible to use a confounder to change A and B so that they now look like they do interact. Clearly there is an infinite set of potential causal interpretations of the same partially observed signals.",
          "summary": "The paragraph discusses the confounding problem in causal inference, highlighting the impossibility of estimating causal effects due to unobserved variables.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "For example, let us say we are interested in the interactions between two neurons. Further, let us assume that there is a third neuron (confounder) that activates both neurons. In that case, if we see a correlation between the neurons we cannot know if it is due to the neurons interacting directly or through an induced interaction by the unobserved neuron. More generally, any joint distribution between two neurons could be induced by a single third neuron. Unobserved neurons or information can act as confounders for the inference of eC, threatening the validity of the results. This confounding problem is central to the statistical field of causal inference and it is generally acknowledged that, in typical situations, unobserved confounders render inferences about causality impossible.",
          "summary": "The paragraph provides an example of confounding in neuron interactions, emphasizing the challenge it poses to causal inference.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "We want to use Simpson's paradox to highlight the threat of confounding [43], in which unobserved interaction can either cancel out main effects, or artificially induce spurious main effects. Let us say that there are two brain states (e.g. related to two levels of attention), and that one state is associated with high activity of neuron A and low activity of neuron B while another is associated with low activity of neuron A and high activity of neuron B. But let us say that there is a positive instantaneous causal influence from one on the other. If we do not know the brain state (confounded) we may conclude that neuron A has a negative influence on the activity of neuron B. However, if we do know the brain state, we correctly see that A increases the activity of neuron B (Figure 1). This paradox shows how confounders with relevant structure can arbitrarily influence the resulting eC and can effectively destroy it.",
          "summary": "The paragraph uses Simpson's paradox to illustrate how confounding can mislead causal inference in brain state analysis.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "Indeed, in certain neuroimaging datasets it is possible to directly observe Simpson’s paradox. For instance, the choice of analysis parameters, such as seed regions, and the network they belong to, may mediate whether different FC methods yield similar, or orthogonal results [44]. Moreover, functional brain parcellations reconfigure based on the brain state [45].",
          "summary": "The paragraph discusses the observation of Simpson's paradox in neuroimaging datasets and the impact of analysis parameters.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "The paragraph lacks a clear conclusion or key takeaway.",
              "severity": "major",
              "recommendation": "Add a concluding sentence to summarize the implications of the observations."
            }
          ]
        },
        {
          "text": "These issues would maybe be a minor problem if we had reasons to believe that confounding is weak, i.e. if there were few unobserved confounders and that they would be weak. However, we will demonstrate that we have no reason to believe so, and that the number of such confounders is in fact larger by orders of magnitude (and their strength arguably roughly the same) than the observed signals. We will argue, based on the omitted variable bias equation (Box 2) that it is highly unlikely that an algorithm could identify the network of causal interactions.",
          "summary": "The paragraph argues that confounding is a significant issue due to the large number of strong unobserved confounders.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        }
      ]
    },
    {
      "name": "The omitted variable bias (OVB)",
      "paragraphs": [
        {
          "text": "Neuroimaging datasets (e.g. fMRI and MEG) are affected by obvious confounders including head motion and physiological processes. One dominant view is that correcting for obvious confounders improves causal inference irrespective of unobserved confounders [2]. However, for each obvious external controllable confounder there are countless internal unobservable ones [46]. Hence, while we agree that correcting for observed confounders improves the prediction of models, we argue that such view remains speculative when it comes to inferring causality for theoretical reasons that we lay out below.",
          "summary": "The paragraph discusses the impact of confounders on neuroimaging datasets and questions the effectiveness of correcting for observed confounders in causal inference.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "For better illustration, we refer to a linear system (see Box 2). However, we note that OVB equally applies to nonlinear systems [47,48] as, the existence of unobserved variables introduces a bias that persists, regardless the amount of data. Given the nature of recorded brain signals, there is no reason to believe that the observed variables (e.g. average activation in a voxel) should have more causal influence than the unobserved variables (e.g. any represented variable orthogonal to this). Signals recorded in neuroscience usually entail millions more unobserved signals than observed signals [49,50]. Hence, the unobserved noise is expected to be arbitrarily larger than the signal obtained from observed neural activity. Therefore, statistical techniques will fail to reveal causal insights from correlations unless we have strong additional prior knowledge about the system and its dynamics.",
          "summary": "The paragraph explains the persistence of omitted variable bias in both linear and nonlinear systems, emphasizing the challenge posed by unobserved variables in neuroscience.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "One sentence exceeds 40 words, affecting readability.",
              "severity": "major",
              "recommendation": "Break down long sentences into shorter ones to improve readability."
            }
          ]
        }
      ]
    },
    {
      "name": "Box 2. Mathematical demonstration of the omitted variable bias",
      "paragraphs": [
        {
          "text": "Let us assume that there is a set of variables x that are observed. We want to ask what the causal influence of x is on y. Both x and y may be neural activities that relate in a linear way to each other:",
          "summary": "Introduction to the problem of determining causal influence between observed variables x and y.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "+z𝛿  (1)",
          "summary": "Equation representing the relationship between variables.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": false,
            "topicContinuity": false,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Equation presented without context or explanation.",
              "severity": "critical",
              "recommendation": "Provide context or explanation for the equation."
            }
          ]
        },
        {
          "text": "where  is the weight for the influence that signal x has on y. Further, 𝛿 is the weight of the noise term z, which includes other variables that we do not observe but that also have a causal influence on x and y. These unobserved variables introduce OVB onto the causal estimate of the influence of x and y. Importantly, OVB cannot be overcome by more data, it exists in the limit of infinite sized datasets. Further, following a simple back of the envelope calculation for the relevant effects studied in the FC and EC fields, OVB should, be orders of magnitude larger than the real signals, entirely rendering the techniques useless for their typical applications.",
          "summary": "Explanation of the weights and the impact of unobserved variables on causal estimates.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Sentence length exceeds recommended limits.",
              "severity": "major",
              "recommendation": "Break down long sentences into shorter, clearer ones."
            }
          ]
        },
        {
          "text": "When we apply a linear regression model, we typically ignore z and calculate as a mean square error estimate:",
          "summary": "Introduction to the application of linear regression models ignoring noise.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "(2)",
          "summary": "Equation representing the mean square error estimate.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": false,
            "topicContinuity": false,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Equation presented without context or explanation.",
              "severity": "critical",
              "recommendation": "Provide context or explanation for the equation."
            }
          ]
        },
        {
          "text": "However, once we take the noise (z) into account, we can insert the equation for y (1) into the equation for :",
          "summary": "Discussion on incorporating noise into the regression model.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "(3)",
          "summary": "Equation showing the modified regression model with noise.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": false,
            "topicContinuity": false,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Equation presented without context or explanation.",
              "severity": "critical",
              "recommendation": "Provide context or explanation for the equation."
            }
          ]
        },
        {
          "text": "In other words, the existence of unobserved variables introduces a bias that persists, regardless the amount of data (X). There is no reason to believe that the  contribute more variance than the . The correlations between x and z are typically relatively high [51]. In fact, neural signals recorded in neuroscience usually entail millions more unobserved signals than observed signals [49]. Hence, the signal from the z term is expected to be arbitrarily larger than the signal from x and statistical techniques are highly susceptible to OVB when applied to merely observational data.",
          "summary": "Explanation of the persistent bias introduced by unobserved variables.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Sentence length exceeds recommended limits.",
              "severity": "major",
              "recommendation": "Break down long sentences into shorter, clearer ones."
            }
          ]
        },
        {
          "text": "As the neural dimensionality (or speed of processing) in each measured signal increases, the temporal resolution decreases, the noise (or non-communication related signal) increases and hence the idea of extracting causality from observation becomes hopeless. Importantly, this is not a problem that can simply be solved by recording data from more subjects. This is a case where a problem can fundamentally not be solved.",
          "summary": "Discussion on the limitations of extracting causality due to increased noise.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        }
      ]
    },
    {
      "name": "The number of confounders is astronomical",
      "paragraphs": [
        {
          "text": "Omitted variable biases will make causal inference impossible if there are many unobserved dimensions relative to the observed dimensions. For instance, when analyzing spike data, there are far more unobserved variables than observed variables. When we record a few hundred neurons [52], the number of recorded neurons is a vanishingly small subset of all neurons. We have little reason to assume that the recorded neurons are much more important than the un-recorded neurons. As each neuron receives inputs from so many other un-recorded neurons, we should expect that the parts of neural activity driven by unobserved neurons are arbitrarily larger than the parts coming from observed neurons. In other words, the confounding signal should be many orders of magnitude more important than those coming from observed data. As such, we should not expect that causal inference is possible.",
          "summary": "The paragraph discusses the challenge of omitted variable biases in causal inference due to the large number of unobserved variables compared to observed ones in neural data.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "We might feel that causality may happen at a given scale, which would make the argument about unobserved dimensions invalid and allowing a multi-scale definition of interactions. The argument given is often the analogy to statistical physics: while understanding the interaction between individual gas molecules becomes quickly hopeless, a large set of gas atoms can be well understood in terms of temperature and pressure. However, this analogy quickly breaks down when applied to neurophysiology. Every neuron is special in the sense that they do not interact with random neurons, but with a largely fixed set, or worse, a set that changes through neuroplasticity. The justification of averaging over molecules is often perfectly fine in statistical physics. However, whether this this logic works in neuroscience remains an open question.",
          "summary": "The paragraph critiques the analogy between statistical physics and neurophysiology, arguing that neurons interact in complex, non-random ways unlike gas molecules.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "When analyzing imaging data such as fMRI, or LFP, EEG, or MEG, there are also far more unobserved variables than observed variables. Within each signal source, we can, in some abstraction, observe the sum of neural activity. However, the same measured activity can be realized by any combination of individual activities rendering a solution of the inverse problem (signals 🡪 neuronal spike trains) infeasible. The activity of neurons which are orthogonal to our signal, can span arbitrary dimensions, related to movement, memory, thought or neuronal communication. Importantly, dense physiological recordings in small areas suggest that countless variables are represented (e.g. movement related signals in V1; Musall et al., 2018; Stringer et al., 2018). The signals that we can measure are arbitrarily low-dimensional relative to the full dimensionality of communication in the brain. As such we are still in the situation where we have a number of confounders that is many orders of magnitude larger than the number of measured variables. This again puts us into the domain where causal inference should be impossible.",
          "summary": "The paragraph highlights the challenge of inferring causality from imaging data due to the overwhelming number of unobserved variables compared to observed ones.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Some sentences exceed the recommended length, increasing cognitive load.",
              "severity": "major",
              "recommendation": "Break longer sentences into shorter, more manageable ones."
            }
          ]
        },
        {
          "text": "Macroscopic recording (such as fMRI) is what, to many people, hides the underlying logical problems of confounding. We record from a number of voxels or pixels. In many cases, we cover the whole brain. So where do the confounders hide? Within each voxel there are generally millions of neurons that form billions of synapses [50]. However, we only observe the macroscopic activities, say the sum of all activities. This means that all the dimensions that are uncorrelated to this sum continue to exist and continue to be transmitted to other voxels. In other words, there is nothing about the setting that removes confounders, unless the voxel activity itself is the confounder. Given that the majority of dimensions is unobserved, the probability of recording the confounder is vanishingly small.",
          "summary": "The paragraph discusses how macroscopic recordings like fMRI obscure the presence of confounders due to the vast number of unobserved neuronal activities.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "It has been argued that statistical approaches may still uncover low-dimensional organization between brain regions [2]. The argument is that if the brain’s activity was very low dimensional and aligned with recorded dimensions [55], then recording from a small number of voxels or neurons may be equivalent to recording all of them. Such view assumes that we believe that the composition of the activity within a voxel, for instance, does not matter but just the measured sum of (unobserved) individual activities. We thereby effectively subscribe to a strong mean-field view, which is dominant among eC methodology [56–59]. However, within each voxel, we find neurons of countless tuning properties [60] that describe how neurons are affected by a stimulus dimension such as color. On a theoretical level, it thus becomes clear how mean-field or ensemble averaging techniques fall risk of violating ergodicity principles as a key assumption of cause-effect inference, i.e. that the mean response of representative samples allow predictions about individual members of those samples [61]. On a practical level, model inferences becomes easily biased when algorithms that compute eC based on mean-field variables (e.g. the average activity within several voxels informed by some parcellation) miss relevant nodes [45,51]. Lastly we argue that effectively, mean-field studies set up simulations that unfold in low-dimensional spaces and then show that they can be recovered in low-dimensional spaces, rendering the approach somewhat circular [56–59]. To our knowledge no study has shown that networks that compute like brains can be approximated by the underlying mean-field approximation. Barring such a study we should assume that mean-field is not a meaningful approximation of brain computation.",
          "summary": "The paragraph critiques the mean-field approach in neuroscience, arguing it may not accurately represent brain computation due to its assumptions and potential biases.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Some sentences exceed the recommended length, increasing cognitive load.",
              "severity": "major",
              "recommendation": "Break longer sentences into shorter, more manageable ones."
            }
          ]
        },
        {
          "text": "Typically applied eC algorithms are unable to disentangle correlational from causal sources of variability regardless their mathematical sophistication [3,61]. Causal inference algorithms that work with observational data are generally built on the assumption of causal sufficiency, which boils down to there being no unobserved confounders (although see Ranganath and Perotte, 2018; Wang and Blei, 2018) – this assumption within neuroscience is that all neurons are recorded from. Without these assumptions we can at best produce families of potential models and if any pair of recorded variables is confounded then this family will contain all models [64]. Recording only a few variables in a densely interacting causal system generally renders causal inference impossible [20,65].",
          "summary": "The paragraph discusses the limitations of eC algorithms in distinguishing correlation from causation due to the assumption of causal sufficiency.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        }
      ]
    },
    {
      "name": "Why higher resolution is not the solution",
      "paragraphs": [
        {
          "text": "We may ask if causal inference may work for exhaustively recorded (i.e., completely observed) neural networks, for instance in small animals or engineered systems. In the worm c. elegans, aplysia, drosophila, larval zebrafish [66] or microprocessors [67] recording all “neurons” at high temporal precision is possible. For instance, in very small simulated systems that contain only a few interconnected neurons we may find that correlation approaches true, causal connectivity (https://compneuro.neuromatch.io/tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial2.html). However, once the network becomes larger (or, equivalently, there being stronger spatial autocorrelation, estimated and true connectivity diverge, and model identification becomes impossible (Figure 2). Likewise, model inference based on merely observational data (i.e. network correlations) becomes impossible in larger, interconnected systems. This is because mismatches between the generative system and the inference model (i.e. model mis-specification) become inevitable , and highly correlated, yet not directly coupled activity (as typically observed in recurrent networks) will be easily mistaken for direct connections [51]. This underdetermination (or “missing region” problem and the bias it introduces is well known [29,51] and only controlled perturbations can prevent such systematic inference errors [51,68].",
          "summary": "The paragraph discusses the challenges of causal inference in neural networks, particularly as network size increases.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "Some sentences exceed 40 words, increasing cognitive load.",
              "severity": "major",
              "recommendation": "Break long sentences into shorter ones to improve readability."
            },
            {
              "issue": "Lack of structural parallelism in presenting examples.",
              "severity": "minor",
              "recommendation": "Use a consistent structure when listing examples or concepts."
            }
          ]
        },
        {
          "text": "As the impossibility of causal inference from subsampled data may feel counter-intuitive we want to spell out the problem a bit more. Let us assume we are interested in the connections between two signals, e.g. voxels B and C. However, we note the brain’s real dynamics are characterized by the activity of up to more than 5 million neurons contained in these voxels [50]. In its simplest form, these can be modelled as a linear system that includes a noise term for unexplained variance. As the neural dimensionality (or speed of processing) in each measured signal increases, the noise (or non-communication related signal) increases and hence the idea of extracting causality from observation becomes hopeless. Importantly, this is not a problem that can simply be solved by recording data from more observations. Increasing data can only decrease variance errors but not bias errors, which result from correlated neural activities that are not averaged out by merely increasing data [51]. Bias errors will persist unless perturbations are applied [51].",
          "summary": "The paragraph explains why causal inference from subsampled data is problematic, emphasizing the role of noise and bias errors.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "For all methods that we have at our disposal to run functional connectivity analyses, the signals are few relative to the many unobserved variables. In these settings, interactions between measured signals should describe much less variance than the interactions between unobserved variables. While the examples we discuss here focus on neuron-to-neuron interactions, additional complexity arises from interactions with other cell types such as glia. Just like in Simpson’s paradox, the interactions between such unobserved variables can arbitrarily affect the estimates of interactions between measured signals [49]. As the neural dimensionality in each measured signal increases, the noise (or non-communication related signal) increases and interactions between unobserved variables can arbitrarily affect the estimates of interactions between measured signals, resulting in OVB [68]. Hence, all reviewed statistical methods are ultimately susceptible to OVB [48,69,70].",
          "summary": "The paragraph discusses the limitations of functional connectivity analyses due to unobserved variables and their impact on observed signal interactions.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Some sentences exceed 40 words, increasing cognitive load.",
              "severity": "major",
              "recommendation": "Break long sentences into shorter ones to improve readability."
            }
          ]
        }
      ]
    },
    {
      "name": "Correct “estimated connectivity” from perturbations",
      "paragraphs": [
        {
          "text": "A continuum of perturbation approaches to study causal interactions in brain activity are available in the neurosciences that should motivate future developments [19]. Counterfactual, causal inference ideas can be used to assess the strength of evidence about causality that can be obtained with commonly used approaches. Considerations of the Bradford-Hill criteria, provide a starting point for future research on causality in neuroscience. These perturbation studies also come with limitations, e.g. sources of confounding and still limited understanding of involved mechanisms [73,74]. Istill for those studies However, perturbation and in particular (passive) brain stimulation techniques are currently as close as we can get to causality in neuroscience when employed in a randomized, adequately controlled and blinded way [75].",
          "summary": "The paragraph discusses the availability and limitations of perturbation approaches in neuroscience for studying causal interactions.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Sentence length exceeds recommended average, with some sentences being complex.",
              "severity": "major",
              "recommendation": "Break down longer sentences into shorter, more manageable ones."
            },
            {
              "issue": "Typographical error 'Istill' present.",
              "severity": "minor",
              "recommendation": "Correct the typographical error to improve readability."
            }
          ]
        },
        {
          "text": "Emerging techniques for perturbations may confront us with new conceptual problems. Perturbation techniques such as neurofeedback training and brain computer interfaces (BCIs) may be seen as an approximation to direct perturbations [79], because they allow to entrain correlations between brain regions and test for desired behavioral changes and have thus been advocated as tools for trying to understand causality within the brain [80–82]. BCIs synchronized in multiple users (so called hyperscanning) provide a special use case that allows closed-loop control of neural synchrony. These developments have recently initiated debates about causal inferences that can be drawn from well-controlled BCI experiments [83–86]. As complex interventions BCIs entail various obvious confounders and require experiments with (often many) carefully designed control conditions [87]. Combining BCIs with brain stimulation techniques may circumvent some limitations of other approaches. Further, complementary invasive closed-loop optogenetic stimulation studies conducted in animals, where stimulation is triggered by learned neural activity patterns [88], may circumvent some of the confounders and provide converging evidence [19,89]. Conceptual work is needed, however, to obtain clarity about these interpretations.",
          "summary": "The paragraph explores emerging perturbation techniques and their conceptual challenges, focusing on BCIs and their implications for causal inference.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Sentence length exceeds recommended average, with some sentences being complex.",
              "severity": "major",
              "recommendation": "Simplify complex sentences and break them into shorter ones."
            }
          ]
        },
        {
          "text": "Lastly, clinical applications often use eC measures, not to quantify causal interactions but as a proxy for hard-to measure behavioral effects. Clinicians ask if interventions affect eC as “biomarkers”. Brain stimulation techniques can thus be “eC-navigated”, i.e. targets are defined based on eC measures that predict (individual) clinical outcomes [90]. Brain Computer interfaces (BCIs) can target eC measures using eC changes as readily optimizable targets [83,91]. eC may be the best quantitative biomarkers for intervention effects when tested in adequately designed randomized controlled trials. They may also enable a quest to understand if low-dimensional organization principles can approximate causality [2]. However, research based on eC biomarkers remain somewhat circular field where changes in low-dimensional space are used to justify low-dimensional assumptions (e.g. mean-field based eC between two brain regions). Thus, causal insight about eC biomarkers (e.g. when used in eC-navigated perturbations) will require converging evidence [19] across organisational levels of the nervous system (i.e. molecular mechanisms) [49] and, above all, tests based on perturbations.",
          "summary": "The paragraph discusses the use of eC measures in clinical applications as proxies for behavioral effects and their implications for understanding causality.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "Sentence length exceeds recommended average, with some sentences being complex.",
              "severity": "major",
              "recommendation": "Divide longer sentences into shorter, clearer ones to improve readability."
            }
          ]
        }
      ]
    },
    {
      "name": "Concluding remarks",
      "paragraphs": [
        {
          "text": "We have reviewed why eC approaches cannot meaningfully get at causality due to massive confounding from unobserved variables – correlations are not causation and omitted variables produce biases. However, this circumstance does not imply that trying to understand the joint dynamics of many neurons or brain areas is not interesting. For example, looking at the brain in lower dimensional projections may allow us to see its invariances [92–94]. Interregional correlations may have no causal meaning, but they may allow us to derive biomarkers [95–97]. To which degree these reflect neuronal interactions, however, remains subject to future perturbational, well controlled studies. Understanding joint statistics of neurons or brain networks is highly informative, however, statements about joint statistics are not meaningful statements about causality – it is important to be clear about the statements permitted by any one approach. In cases where these cannot be substantiated, only descriptive approaches [98] non-causal explanations are informative and meaningful [25,99]. Lastly, we note that there may be also a sociological dimension to the raised issues: authors often seem incited to make causal statements using filler verbs (e.g. to drive, alter, promote) as a form of storytelling [21] to leverage the perceived attractiveness of their work. Instead of committing this fallacy, we encourage researchers to question the causal validity of statements, probe underlying assumptions and test counterfactual inference boundaries (see Outstanding questions).",
          "summary": "The paragraph discusses the limitations of eC approaches in establishing causality, the potential value of understanding joint dynamics of neurons, and the sociological factors influencing causal claims in research.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "The paragraph lacks a clear context-content-conclusion structure.",
              "severity": "major",
              "recommendation": "Reorganize the paragraph to clearly introduce the topic, provide supporting content, and conclude with a key takeaway."
            },
            {
              "issue": "Average sentence length exceeds 25 words, and some sentences are complex.",
              "severity": "major",
              "recommendation": "Break down longer sentences into shorter, more manageable ones to improve readability."
            },
            {
              "issue": "The paragraph lacks structural parallelism, particularly in presenting examples and recommendations.",
              "severity": "minor",
              "recommendation": "Use parallel grammatical structures when listing examples or recommendations to enhance readability."
            }
          ]
        }
      ]
    },
    {
      "name": "Outstanding questions",
      "paragraphs": [
        {
          "text": "What is an adequate nomenclature for causality inferences in neuroscience that reflects the different degree of uncertainty associated with individual approaches?",
          "summary": "The paragraph questions the appropriate terminology for causality inferences in neuroscience.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "The paragraph lacks a content and conclusion section.",
              "severity": "critical",
              "recommendation": "Expand the paragraph to include elaboration on the topic and a concluding statement."
            }
          ]
        },
        {
          "text": "For which questions do we need causality? For instance, clinical research may find biomarkers that indicate a disease state but are not part of the causal chain or about which we have little mechanistic insight. Yet, they may be suitable to predict disease trajectories or treatment response.",
          "summary": "The paragraph discusses the necessity of causality in clinical research, particularly in relation to biomarkers.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": []
        },
        {
          "text": "What are the counterfactual inference boundaries for perturbation approaches and how can these be considered with adequate analyses? There are several approaches that may be useful, for instance tests and simulation studies that investigate under which circumstances there is likely confounding by Simpson’s paradox. In neural systems that are fully described, targeted perturbations can be used to probe whether algorithms can reconstruct expected patterns.",
          "summary": "The paragraph explores the boundaries of counterfactual inference in perturbation approaches and suggests methods for analysis.",
          "evaluations": {
            "cccStructure": true,
            "sentenceQuality": false,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": true
          },
          "issues": [
            {
              "issue": "The average sentence length exceeds 25 words.",
              "severity": "major",
              "recommendation": "Break down longer sentences into shorter, more manageable ones."
            }
          ]
        },
        {
          "text": "Which mechanisms underly effects of perturbational approaches such as brain stimulations and BCIs? How can study protocols for combined perturbational approaches be optimized to yield converging causal mapping?",
          "summary": "The paragraph questions the mechanisms behind perturbational approaches and how protocols can be optimized.",
          "evaluations": {
            "cccStructure": false,
            "sentenceQuality": true,
            "topicContinuity": true,
            "terminologyConsistency": true,
            "structuralParallelism": false
          },
          "issues": [
            {
              "issue": "The paragraph lacks a content and conclusion section.",
              "severity": "critical",
              "recommendation": "Provide elaboration on the mechanisms and optimization strategies, followed by a concluding statement."
            }
          ]
        }
      ]
    }
  ]
}